{
  "fileName": "hashing_discretizer.cpp",
  "filePath": "twml/libtwml/src/ops/hashing_discretizer.cpp",
  "url": "https://github.com/misbahsy/the-algorithm/twml/libtwml/src/ops/hashing_discretizer.cpp",
  "summary": "The `HashingDiscretizer` operation discretizes a tensor containing continuous features, if calibrated. The operation maps observation vectors to higher dimensional observation vectors. The input to the operation is a tensor containing input feature IDs, a tensor containing input values at corresponding feature IDs, and a tensor containing the bin boundaries for values of a given feature. The output of the operation is the discretized feature IDs and the discretized values with the same shape and size as the input keys and values.\n\nThe operation constructs a hash map of feature IDs to their corresponding indices. For each feature, the operation associates a (discrete, finite) set of new feature IDs, newIDs(F). The operation maps (F,x) to (map(x|F),1), where map(x|F) is a new feature ID, and the value observed for that feature is 1. Each set member of newIDs(F) is associated with a 'bin', as defined by the bin boundaries given in the bin_vals input array. For any two different feature IDs F and G, the intersection of newIDs(F) and newIDs(G) is not guaranteed to be the empty set.\n\nThe operation uses hashing to construct map(x|F). Let bucket be the bucket index for x, according to the calibration on F. Then, map(x|F) = hash_fn(F,bucket). This has the desirable property that the new ID depends only on the calibration data supplied for feature F, and not on any other features in the dataset. Note that PercentileDiscretizer does not have this property. This comes at the expense of the possibility of output ID collisions, which the operation tries to minimize through the design of hash_fn.\n\nThe operation takes several attributes, including the number of bin boundary values per feature, the maximum number of bits to use for the output IDs, an estimate of the number of CPU cycles (or nanoseconds if not CPU-bound) to complete a unit of work, and options that select the behavior of the operation. The operation is implemented in C++ and registered for use with float and double data types.",
  "questions": "1. What is the purpose of this code and what problem does it solve?\n- This code implements a hashing discretizer operation that discretizes a tensor containing continuous features. It maps observation vectors to higher dimensional observation vectors by associating a (discrete, finite) set of new feature IDs with each feature, and then mapping each observation to a new feature ID based on its value and the bin boundaries given in the input array.\n2. What are the inputs and outputs of this operation?\n- The inputs are:\n  - `input_ids`: a tensor containing input feature ids (direct from data record).\n  - `input_vals`: a tensor containing input values at corresponding feature ids.\n  - `bin_vals`: a tensor containing the bin boundaries for values of a given feature.\n  - `feature_ids`: a 1D TensorProto of feature IDs seen during calibration.\n  - `n_bin`: the number of bin boundary values per feature.\n  - `output_bits`: the maximum number of bits to use for the output IDs.\n  - `cost_per_unit`: an estimate of the number of CPU cycles (or nanoseconds if not CPU-bound) to complete a unit of work.\n  - `options`: selects behavior of the op.\n- The outputs are:\n  - `new_keys`: the discretized feature ids with same shape and size as keys.\n  - `new_vals`: the discretized values with the same shape and size as vals.\n3. What is the purpose of the `ID_to_index` hash map and how is it constructed?\n- The `ID_to_index` hash map is used to map feature IDs to their corresponding indices in the `feature_ids` tensor. It is constructed by iterating over the `feature_ids` tensor and inserting each ID-index pair into the hash map."
}