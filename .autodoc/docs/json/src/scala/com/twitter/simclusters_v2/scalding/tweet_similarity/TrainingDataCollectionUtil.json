{
  "fileName": "TrainingDataCollectionUtil.scala",
  "filePath": "src/scala/com/twitter/simclusters_v2/scalding/tweet_similarity/TrainingDataCollectionUtil.scala",
  "url": "https://github.com/misbahsy/the-algorithm/src/scala/com/twitter/simclusters_v2/scalding/tweet_similarity/TrainingDataCollectionUtil.scala",
  "summary": "The `TrainingDataCollectionUtil` object is used to collect training data for supervised tweet similarity. It contains methods to split the dataset into train and test datasets based on time or query, and to write the resulting datasets to disk. \n\nThe `splitRecordsByTime` method takes an input dataset and a test start date, and returns a tuple of train and test datasets. The method partitions the input dataset into two sets based on whether the tweets were engaged before or after the test start date. The tweets engaged before the test start date are used for training, and the tweets engaged after the test start date are used for testing. The method returns a tuple of train and test datasets.\n\nThe `splitRecordsByQuery` method takes an input dataset and a test ratio, and returns a tuple of train and test datasets. The method partitions the input dataset into two sets based on the query tweet ID. It randomly assigns a number between 0 and 1 to each query tweet ID, and uses this number to determine whether the tweet is used for training or testing. The tweets with a random number greater than the test ratio are used for training, and the tweets with a random number less than or equal to the test ratio are used for testing. The method returns a tuple of train and test datasets.\n\nThe `getTrainTestByTimeExec` method takes an input dataset, a test start date, and output paths for the train and test datasets. It returns an execution of the writing exec. The method uses the `splitRecordsByTime` method to split the input dataset into train and test datasets. It then writes the train and test datasets to disk using the `writeDALExecution` method. It also computes and writes the statistics of the train and test datasets using the `getStatsExec` method.\n\nThe `getTrainTestByQueryExec` method takes an input dataset, a test ratio, and output paths for the train and test datasets. It returns an execution of the writing exec. The method uses the `splitRecordsByQuery` method to split the input dataset into train and test datasets. It then writes the train and test datasets to disk using the `writeDALExecution` method. It also computes and writes the statistics of the train and test datasets using the `getStatsExec` method.\n\nThe `getStatsExec` method takes a dataset and an output path, and returns an execution of the writing exec. The method computes the number of positive and negative records in the dataset based on whether the tweets are co-engaged or not. It then writes the statistics to disk using the `writeExecution` method.\n\nOverall, the `TrainingDataCollectionUtil` object provides methods to split the dataset into train and test datasets based on time or query, and to write the resulting datasets to disk. These methods are used to collect training data for supervised tweet similarity.",
  "questions": "1. What is the purpose of this code?\n- This code is for collecting training data for supervised tweet similarity.\n\n2. What are the inputs and outputs of the `splitRecordsByTime` function?\n- The input is a `DataSetPipe` and a `RichDate`. The output is a tuple of two `DataSetPipe`s representing the train and test datasets.\n\n3. What is the purpose of the `getStatsExec` function?\n- The purpose of the `getStatsExec` function is to generate an execution for reporting dataset statistics, such as the total number of positive and negative records."
}